/////////////////toy problem Maximum array sum/////////////////////
def max_subarray_sum(arr):
    max_current = max_global = arr[0]

    for i in range(1, len(arr)):
        max_current = max(arr[i], max_current + arr[i])
        max_global = max(max_global, max_current)

    return max_global

input_array = [-2,-3,4,-1,-2,1,5,-3]
result = max_subarray_sum(input_array)
print(input_array)
print(result)


///////nqueens////////////////////////////////////////////////
def is_safe(board, row, col):
    # Check if there is a queen in the same column
    for i in range(row):
        if board[i][col] == 1:
            return False

    # Check upper left diagonal
    for i, j in zip(range(row, -1, -1), range(col, -1, -1)):
        if board[i][j] == 1:
            return False

    # Check upper right diagonal
    for i, j in zip(range(row, -1, -1), range(col, len(board))):
        if board[i][j] == 1:
            return False

    return True

def solve_n_queens(board, row):
    n = len(board)
    if row >= n:
        return True

    for col in range(n):
        if is_safe(board, row, col):
            board[row][col] = 1

            if solve_n_queens(board, row + 1):
                return True

            board[row][col] = 0

    return False

def print_solution(board):
    for row in board:
        print(" ".join(map(str, row)))

n = int(input("Enter the value of N: "))
board = [[0] * n for _ in range(n)]

if solve_n_queens(board, 0):
    print("Solution:")
    print_solution(board)
else:
    print("No solution exists.")

//////////////simple reflexive agent////////////////

def simple_reflex_agent(percept):
    location, status = percept
    if status == "Dirty":
        return "Suck"
    elif location == "A":
        return "Right"
    elif location == "B":
        return "Left"

# Test the agent with sample percepts
percept = ("A", "Dirty")
action = simple_reflex_agent(percept)
print("Percept:", percept)
print("Action:", action)

///////////////////// Bin packing problem ////////////////////////
def first_fit_decreasing(item_sizes, bin_capacity):
    # Sort the items in decreasing order
    sorted_items = sorted(item_sizes, reverse=True)
    bins = [[]] # Start with one bin
    for item in sorted_items:
        # Try to place the item in the first bin where it fits
        for bin in bins:
            if sum(bin) + item <= bin_capacity:
                bin.append(item)
                break

        else:
            bins.append([item])

    return bins

def print_bins(bins):
    for i, bin in enumerate(bins):
        print(f"Bin {i+1}: {bin}")

if __name__ == "__main__":
    # Example usage
    item_sizes = [4, 8, 1, 4, 2, 5, 3]
    bin_capacity = 10
    bins = first_fit_decreasing(item_sizes, bin_capacity)
    print("Bins after packing items:")
    print_bins(bins)


/////////////////////////////breadth fs/////////////
from collections import defaultdict, deque

class Graph:
    def _init_(self):
        self.graph = defaultdict(list)

    def add_edge(self, u, v):
        self.graph[u].append(v)

    def bfs(self, start):
        visited = set()
        queue = deque([start])
        visited.add(start)

        while queue:
            vertex = queue.popleft()
            print(vertex, end=" ")

            for neighbor in self.graph[vertex]:
                if neighbor not in visited:
                    visited.add(neighbor)
                    queue.append(neighbor)

# Test the BFS function
g = Graph()
g.add_edge(0, 1)
g.add_edge(0, 2)
g.add_edge(1, 2)
g.add_edge(2, 0)
g.add_edge(2, 3)
g.add_edge(3, 3)

print("BFS Traversal starting from vertex 2:")
g.bfs(2)

///////////////////dfs////////////////////////

from collections import defaultdict

class Graph:
    def _init_(self):
        self.graph = defaultdict(list)

    def add_edge(self, u, v):
        self.graph[u].append(v)

    def dfs_util(self, vertex, visited):
        visited.add(vertex)
        print(vertex, end=" ")

        for neighbor in self.graph[vertex]:
            if neighbor not in visited:
                self.dfs_util(neighbor, visited)

    def dfs(self, start):
        visited = set()
        self.dfs_util(start, visited)

# Test the DFS function
g = Graph()
g.add_edge(0, 1)
g.add_edge(0, 2)
g.add_edge(1, 2)
g.add_edge(2, 0)
g.add_edge(2, 3)
g.add_edge(3, 3)

print("DFS Traversal starting from vertex 2:")
g.dfs(2)

//////////////////////best fs////////////////////
from queue import PriorityQueue

class Graph:
    def _init_(self):
        self.graph = {}

    def add_edge(self, u, v, weight):
        if u not in self.graph:
            self.graph[u] = []
        self.graph[u].append((v, weight))

    def best_first_search(self, start, goal):
        visited = set()
        pq = PriorityQueue()
        pq.put((0, start))

        while not pq.empty():
            cost, current = pq.get()
            visited.add(current)
            print(current, end=" ")

            if current == goal:
                break

            for neighbor, weight in self.graph.get(current, []):
                if neighbor not in visited:
                    pq.put((weight, neighbor))

# Test the Best-First Search function
g = Graph()
g.add_edge('A', 'B', 5)
g.add_edge('A', 'C', 7)
g.add_edge('A', 'D', 9)
g.add_edge('B', 'E', 6)
g.add_edge('C', 'F', 10)

print("Best-First Search Traversal:")
g.best_first_search('A', 'F')


///////////////////////////a star/////////////////

from queue import PriorityQueue

class Graph:
    def _init_(self):
        self.graph = {}

    def add_edge(self, u, v, weight):
        if u not in self.graph:
            self.graph[u] = []
        self.graph[u].append((v, weight))

    def astar_search(self, start, goal, heuristic):
        visited = set()
        pq = PriorityQueue()
        pq.put((0, start))

        while not pq.empty():
            cost, current = pq.get()
            visited.add(current)
            print(current, end=" ")

            if current == goal:
                break

            for neighbor, weight in self.graph.get(current, []):
                if neighbor not in visited:
                    priority = cost + weight + heuristic(neighbor, goal)
                    pq.put((priority, neighbor))

# Test the A* Search function
g = Graph()
g.add_edge('A', 'B', 5)
g.add_edge('A', 'C', 7)
g.add_edge('A', 'D', 9)
g.add_edge('B', 'E', 6)
g.add_edge('C', 'F', 10)

def heuristic(node, goal):
    # Example heuristic function (can be customized)
    return 0

print("A* Search Traversal:")
g.astar_search('A', 'F', heuristic)


/////////////////////// Fuzzy logic /////////////////////////////////////////
import numpy as np

import skfuzzy as fuzz
from skfuzzy import control as ctrl
# Define input variables
load_size = ctrl.Antecedent(np.arange(0, 11, 1), 'load_size')
dirt_level = ctrl.Antecedent(np.arange(0, 11, 1), 'dirt_level')

washing_time = ctrl.Consequent(np.arange(0, 61, 1), 'washing_time')
# Define membership functions
load_size['small'] = fuzz.trimf(load_size.universe, [0, 0, 5])
load_size['medium'] = fuzz.trimf(load_size.universe, [0, 5, 10])
load_size['large'] = fuzz.trimf(load_size.universe, [5, 10, 10])
dirt_level['low'] = fuzz.trimf(dirt_level.universe, [0, 0, 5])
dirt_level['medium'] = fuzz.trimf(dirt_level.universe, [0, 5, 10])
dirt_level['high'] = fuzz.trimf(dirt_level.universe, [5, 10, 10])
washing_time['short'] = fuzz.trimf(washing_time.universe, [0, 0, 30])
washing_time['medium'] = fuzz.trimf(washing_time.universe, [0, 30, 60])
washing_time['long'] = fuzz.trimf(washing_time.universe, [30, 60, 60])
# Define rules
rule1 = ctrl.Rule(load_size['small'] & dirt_level['low'], washing_time['short']) 
rule2 = ctrl.Rule(load_size['small'] & dirt_level['medium'], washing_time['medium']) 
rule3 = ctrl.Rule(load_size['small'] & dirt_level['high'], washing_time['long'])
rule4 = ctrl.Rule(load_size['medium'] & dirt_level['low'], washing_time['medium'])
rule5 = ctrl.Rule(load_size['medium'] & dirt_level['medium'], washing_time['medium'])
rule6 = ctrl.Rule(load_size['medium'] & dirt_level['high'], washing_time['long'])
rule7 = ctrl.Rule(load_size['large'] & dirt_level['low'], washing_time['medium'])
rule8 = ctrl.Rule(load_size['large'] & dirt_level['medium'], washing_time['long'])
rule9 = ctrl.Rule(load_size['large'] & dirt_level['high'], washing_time['long'])
# Create control system
washing_ctrl = ctrl.ControlSystem([rule1, rule2, rule3, rule4, rule5, rule6, rule7, rule8, rule9])
washing = ctrl.ControlSystemSimulation(washing_ctrl)
# Provide inputs
washing.input['load_size'] = 7
washing.input['dirt_level'] = 8

# Compute the result
washing.compute()
# Print the output
print("Washing time:", washing.output['washing_time'])
washing_time.view(sim=washing)

///////////////////////////////////////uncertain////////////

import random

class MontyHallSimulation:
    def _init_(self, num_trials):
        self.num_trials = num_trials

    def simulate(self):
        switch_wins = 0
        stay_wins = 0

        for _ in range(self.num_trials):
            # Randomly select a door with the car behind it
            car_door = random.randint(1, 3)

            # Contestant makes initial choice
            initial_choice = random.randint(1, 3)

            # Monty reveals a door with a goat behind it that the contestant didn't choose
            remaining_doors = [door for door in range(1, 4) if door != initial_choice and door != car_door]
            monty_reveals = random.choice(remaining_doors)

            # Contestant decides whether to switch or stay
            remaining_doors = [door for door in range(1, 4) if door != initial_choice and door != monty_reveals]
            final_choice = initial_choice  # Uncomment to stay with initial choice
            # final_choice = remaining_doors[0]  # Uncomment to switch doors

            # Check if contestant wins
            if final_choice == car_door:
                if final_choice == initial_choice:
                    stay_wins += 1
                else:
                    switch_wins += 1

        stay_win_percentage = (stay_wins / self.num_trials) * 100
        switch_win_percentage = (switch_wins / self.num_trials) * 100

        print("Simulation results:")
        print("Stay strategy wins: {:.2f}%".format(stay_win_percentage))
        print("Switch strategy wins: {:.2f}%".format(switch_win_percentage))

# Example usage
num_trials = 10000
simulation = MontyHallSimulation(num_trials)
simulation.simulate()


//////////////////////////////unification///////////////////////

def unify(var1, var2, theta):
    if theta is None:
        return None
    elif var1 == var2:
        return theta
    elif isinstance(var1, str) and var1[0].islower():
        return unify_var(var1, var2, theta)
    elif isinstance(var2, str) and var2[0].islower():
        return unify_var(var2, var1, theta)
    elif isinstance(var1, list) and isinstance(var2, list):
        if not var1 or not var2:
            return unify(var1[1:], var2[1:], unify(var1[0], var2[0], theta))
        else:
            return unify(var1[1:], var2[1:], unify(var1[0], var2[0], theta))
    else:
        return None

def unify_var(var, x, theta):
    if var in theta:
        return unify(theta[var], x, theta)
    elif x in theta:
        return unify(var, theta[x], theta)
    else:
        theta[var] = x
        return theta

# Test unification
print(unify('x', 'y', {}))  # {'x': 'y'}
print(unify(['A', 'x'], ['A', 'y'], {}))  # {'x': 'y'}
print(unify(['A', 'B', 'C'], ['A', 'B', 'C'], {}))  # {}


////////////////////////learning algo////////////////

import numpy as np

class Perceptron:
    def _init_(self, learning_rate=0.01, num_epochs=100):
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs

    def fit(self, X, y):
        self.weights = np.zeros(X.shape[1] + 1)
        self.errors = []

        for _ in range(self.num_epochs):
            error = 0
            for xi, target in zip(X, y):
                update = self.learning_rate * (target - self.predict(xi))
                self.weights[1:] += update * xi
                self.weights[0] += update
                error += int(update != 0.0)
            self.errors.append(error)
        return self

    def predict(self, X):
        return np.where(np.dot(X, self.weights[1:]) + self.weights[0] >= 0.0, 1, -1)

# Example usage
X_train = np.array([[2, 3], [4, 5], [6, 7], [8, 9]])
y_train = np.array([1, -1, 1, -1])

model = Perceptron(learning_rate=0.1, num_epochs=10)
model.fit(X_train, y_train)

X_test = np.array([[1, 2], [5, 6]])
predictions = model.predict(X_test)
print("Predictions:", predictions)

/////////////////////////// Ml code RandomForest///////////////////////////

import pandas as pd

melbourne_file_path = 'melb_data.csv'
melbourne_data = pd.read_csv(melbourne_file_path)
melbourne_data = melbourne_data.dropna(axis=0)
y = melbourne_data.Price
melbourne_features = ['Rooms','Bathroom','Landsize','Lattitude','Longtitude']
X = melbourne_data[melbourne_features]
from sklearn.tree import DecisionTreeRegressor

melbourne_model = DecisionTreeRegressor(random_state=1)

melbourne_model.fit(X, y)
print("Making predictions for the following 5 houses: ")
print(X.head())
print("The predictions are")
print(melbourne_model.predict(X.head()))

//////////////////////////////NLP/////////////////////////

import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer

# Sample text
text = "I love this product! It's amazing."

# Initialize VADER sentiment analyzer
sid = SentimentIntensityAnalyzer()

# Analyze sentiment
sentiment_scores = sid.polarity_scores(text)

# Determine sentiment label
if sentiment_scores['compound'] >= 0.05:
    sentiment_label = "Positive"
elif sentiment_scores['compound'] <= -0.05:
    sentiment_label = "Negative"
else:
    sentiment_label = "Neutral"

# Print results
print("Text:", text)
print("Sentiment Scores:", sentiment_scores)
print("Sentiment Label:", sentiment_label)

//////////////////////////////////////DL DL////////////////////

import tensorflow as tf
from tensorflow.keras import layers, models

# Define the model architecture
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])

# Compile the model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Load and preprocess the dataset (e.g., MNIST)
mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

# Reshape the data for CNN input
x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))
x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))

# Train the model
model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))

# Evaluate the model
test_loss, test_acc = model.evaluate(x_test, y_test)
print('Test accuracy:', test_acc)


